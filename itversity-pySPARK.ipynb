{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ITVERSITY CCA-175 Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For LOCAL MACHINE SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<SparkContext master=local appName=ITVERSITY>",
      "text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://DESKTOP-249MU1B.mshome.net:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.5</code></dd>\n              <dt>Master</dt>\n                <dd><code>local</code></dd>\n              <dt>AppName</dt>\n                <dd><code>ITVERSITY</code></dd>\n            </dl>\n        </div>\n        "
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import findspark as fs\n",
    "import os\n",
    "fs.init()\n",
    "fs.find()\n",
    "\n",
    "data_path=os.path.dirname(\"D://Bigdata Tutorials//data//retail_db//\")\n",
    "data_path_json=os.path.dirname(\"D://Bigdata Tutorials//data//retail_db_json//\")\n",
    "\n",
    "from pyspark.sql import SparkSession,SQLContext,HiveContext\n",
    "spark=SparkSession.builder.appName('ITVERSITY').master('local').getOrCreate()\n",
    "sc=spark.sparkContext\n",
    "sqlcontext=SQLContext(sc)\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For VAGRANT SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<SparkContext master=yarn appName=ITVERSITY>",
      "text/html": "\n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.5</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>ITVERSITY</code></dd>\n            </dl>\n        </div>\n        "
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "!start-dfs.sh\n",
    "!start-yarn.sh\n",
    "\n",
    "from pyspark.sql import SparkSession,SQLContext,HiveContext\n",
    "spark=SparkSession.builder.appName('ITVERSITY').master('yarn').getOrCreate()\n",
    "sc=spark.sparkContext\n",
    "sqlcontext=SQLContext(sc)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderItems=sc.textFile(os.path.join(data_path,\"order_items\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderItems=sc.textFile(\"/public/retail_db/order_items\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pyspark.rdd.RDD"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "type(orderItems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# It contains OrderID\n",
    "int(orderItems.first().split(\",\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "299.98"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# It contains Revenue per order Item\n",
    "float(orderItems.first().split(\",\")[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderItemsMap=orderItems.map(lambda x:(int(x.split(\",\")[1]),float(x.split(\",\")[4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(1, 299.98), (2, 199.99), (2, 250.0), (2, 129.99), (4, 49.98)]"
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "orderItemsMap.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can hold 1st element as KEY and reduce the Values using add."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "revenuePerOrder=orderItemsMap.reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1, 299.98)\n(2, 579.98)\n(4, 699.85)\n(5, 1129.8600000000001)\n(7, 579.9200000000001)\n(8, 729.8399999999999)\n(9, 599.96)\n(10, 651.9200000000001)\n(11, 919.79)\n(12, 1299.8700000000001)\n"
    }
   ],
   "source": [
    "for i in revenuePerOrder.take(10): print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations follow LazyEvaluation.\n",
    "\n",
    "#### LazyEvaluation simply uses a DAG(Directed Acyclic Graph) to store all the information related to the Transformations being made.\n",
    "\n",
    "#### As soon as an Action is 'run', spark executes the DAG first and then the action.\n",
    "\n",
    "Let's find DAG of transformations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderItems.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderItemsMap.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenuePerOrder.toDebugString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can open spark job UI and look into DAG visualization.\n",
    "\n",
    "\n",
    "### NOTE: DO NOT USE collect() to preview data in REAL LIFE ENVIRONMENT!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way tp create an RDD is to open a file using open and making a LIST out of it. (a collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productsRaw=open(data_path+\"//products\").read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(productsRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we can create an RDD using Parallelize from the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productsRaw=sc.parallelize(productsRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(productsRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(productsRaw.first())\n",
    "type(productsRaw.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA FRAME\n",
    "\n",
    "#### --provided by sqlContext\n",
    "\n",
    "#### Now we can try loading multiple file formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlcontext.read?\n",
    "\n",
    "##same as spaek.read?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(data_path_json+\"//order_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-------------+-------------------+---------------------+------------------------+-------------------+-------------------+\n|order_item_id|order_item_order_id|order_item_product_id|order_item_product_price|order_item_quantity|order_item_subtotal|\n+-------------+-------------------+---------------------+------------------------+-------------------+-------------------+\n|            1|                  1|                  957|                  299.98|                  1|             299.98|\n|            2|                  2|                 1073|                  199.99|                  1|             199.99|\n|            3|                  2|                  502|                    50.0|                  5|              250.0|\n|            4|                  2|                  403|                  129.99|                  1|             129.99|\n|            5|                  4|                  897|                   24.99|                  2|              49.98|\n+-------------+-------------------+---------------------+------------------------+-------------------+-------------------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=spark.read.format(\"json\").load(data_path_json+\"//order_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "+-------------+-------------------+---------------------+------------------------+-------------------+-------------------+\n|order_item_id|order_item_order_id|order_item_product_id|order_item_product_price|order_item_quantity|order_item_subtotal|\n+-------------+-------------------+---------------------+------------------------+-------------------+-------------------+\n|            1|                  1|                  957|                  299.98|                  1|             299.98|\n|            2|                  2|                 1073|                  199.99|                  1|             199.99|\n|            3|                  2|                  502|                    50.0|                  5|              250.0|\n|            4|                  2|                  403|                  129.99|                  1|             129.99|\n|            5|                  4|                  897|                   24.99|                  2|              49.98|\n+-------------+-------------------+---------------------+------------------------+-------------------+-------------------+\nonly showing top 5 rows\n\n"
    }
   ],
   "source": [
    "df1.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orders and OrderItems Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "u'1,2013-07-25 00:00:00.0,11599,CLOSED'"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "orders=sc.textFile(os.path.join(data_path,\"orders\"))\n",
    "orders.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[u'1,2013-07-25 00:00:00.0,11599,CLOSED',\n u'2,2013-07-25 00:00:00.0,256,PENDING_PAYMENT',\n u'3,2013-07-25 00:00:00.0,12111,COMPLETE',\n u'4,2013-07-25 00:00:00.0,8827,CLOSED',\n u'5,2013-07-25 00:00:00.0,11318,COMPLETE']"
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "orders.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "68883"
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "orders.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract OrderStatus: (YYYYMMDD,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(u'20130725', u'CLOSED')"
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "ordersMap=orders.map(lambda x: (x.split(\",\")[1].split(\" \")[0].replace(\"-\",\"\"),x.split(\",\")[3]))\n",
    "ordersMap.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[u'1,2013-07-25 00:00:00.0,11599,CLOSED',\n u'3,2013-07-25 00:00:00.0,12111,COMPLETE',\n u'4,2013-07-25 00:00:00.0,8827,CLOSED',\n u'5,2013-07-25 00:00:00.0,11318,COMPLETE',\n u'6,2013-07-25 00:00:00.0,7130,COMPLETE']"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "# To get data of COMPLETE ORDERS OR CLOSED orders\n",
    "ordersComplete=orders.filter(lambda x: x.split(\",\")[3] == 'COMPLETE' or x.split(\",\")[3] == 'CLOSED')\n",
    "ordersComplete.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[u'25882,2014-01-01 00:00:00.0,4598,COMPLETE',\n u'25888,2014-01-01 00:00:00.0,6735,COMPLETE',\n u'25889,2014-01-01 00:00:00.0,10045,COMPLETE',\n u'25891,2014-01-01 00:00:00.0,3037,CLOSED',\n u'25895,2014-01-01 00:00:00.0,1044,COMPLETE']"
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "#To get CLOSED/COMPLETE orders in 2014-01\n",
    "ordersComplete=orders.filter(lambda x: (x.split(\",\")[1][:7]=='2014-01') and (x.split(\",\")[3] in ['COMPLETE','CLOSED'] ))\n",
    "ordersComplete.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}